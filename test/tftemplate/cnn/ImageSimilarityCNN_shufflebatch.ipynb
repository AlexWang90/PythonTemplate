{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片重复检测神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/recsys/platform/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "import threading\n",
    "import _thread\n",
    "import codecs\n",
    "import json\n",
    "import multiprocessing\n",
    "from multiprocessing import Process\n",
    "from multiprocessing import Manager\n",
    "from multiprocessing import Queue\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全局变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecords_file = \"/home/recsys/hzwangjian1/data/train.tfrecords\"\n",
    "file_to_write = \"/home/recsys/hzwangjian1/data/imagepath_pair_duplabel.data\"\n",
    "model_path = '/home/recsys/hzwangjian1/data/duplicate_model_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取《图片一路径，图片二路径，标记》数据对\n",
    "def load_data():\n",
    "    file_to_write = \"/home/recsys/hzwangjian1/data/imagepath_pair_duplabel.data\"\n",
    "    reader_handler = open(file_to_write, 'r')\n",
    "\n",
    "    image_one_path_list = []\n",
    "    image_two_path_list = []\n",
    "    label_list = []\n",
    "\n",
    "    count = 0\n",
    "    for line in reader_handler:\n",
    "        count = count + 1\n",
    "        elems = line.split(\"\\t\")\n",
    "        if len(elems) < 3:\n",
    "            print(\"len(elems) < 3:\" + line)\n",
    "            continue\n",
    "        image_one_path = elems[0].strip()\n",
    "        image_two_path = elems[1].strip()\n",
    "        label = int(elems[2].strip())\n",
    "#         if label == 0:\n",
    "#             label = -1\n",
    "\n",
    "        image_one_path_list.append(image_one_path)\n",
    "        image_two_path_list.append(image_two_path)\n",
    "        label_list.append(label)\n",
    "\n",
    "\n",
    "    print(len(image_one_path_list))\n",
    "    print(len(image_two_path_list))\n",
    "    print(len(label_list))\n",
    "    return image_one_path_list, image_two_path_list, label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map多线程、多进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "def creat_thumbnail(image_path):\n",
    "    img = misc.imread(image_path)\n",
    "    img_arr = np.asarray(img)\n",
    "    return img_arr\n",
    "\n",
    "def load_image_with_path_list(image_path_list):\n",
    "#     pool = Pool()\n",
    "    pool = ThreadPool(30)\n",
    "    image_list = pool.map(creat_thumbnail, image_path_list)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# Parameters\n",
    "start_learning_rate = 0.1\n",
    "end_learning_rate = 0.005\n",
    "decay_step = 10000\n",
    "\n",
    "training_iters = 200\n",
    "batch_size = 50\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "image_width = 256\n",
    "image_height = 256\n",
    "image_channel = 3\n",
    "n_input = image_width * image_height\n",
    "\n",
    "# tf Graph input\n",
    "with tf.name_scope('input_data') as scope:\n",
    "    X1 = tf.placeholder(tf.float32, [None, image_width, image_height, image_channel], name='image_one')\n",
    "    X2 = tf.placeholder(tf.float32, [None, image_width, image_height, image_channel], name='image_two')\n",
    "    y = tf.placeholder(tf.float32, [None], name='label')\n",
    "    keep_prob = tf.placeholder(tf.float32, shape=(), name='drop_out') #dropout (keep probability)\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    learning_rate = tf.train.polynomial_decay(start_learning_rate, global_step, decay_step, end_learning_rate,power=3, cycle=False)\n",
    "    \n",
    "\n",
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "variables_dict = {\n",
    "    \"W_conv1\":tf.Variable(tf.random_normal(shape=[11,11, image_channel,32]), name='weight'),\n",
    "    \"b_conv1\":tf.Variable(tf.random_normal(shape=[1,32]), name='bias'),\n",
    "    \n",
    "    \"W_conv2\":tf.Variable(tf.random_normal(shape=[5,5,32,64]), name='weight'),\n",
    "    \"b_conv2\":tf.Variable(tf.random_normal( shape=[1,64]), name='bias'),\n",
    "    \n",
    "    \"W_conv3\":tf.Variable(tf.random_normal(shape=[3,3,64,64]), name='weight'),\n",
    "    \"b_conv3\":tf.Variable(tf.random_normal(shape=[1,64], name='bias')),\n",
    "    \n",
    "    \"W_full\":tf.Variable(tf.random_normal(shape=[8 * 8 * 64, 4096]), name='weight'),\n",
    "    \"b_full\":tf.Variable(tf.random_normal(shape=[1, 4096]), 'bias'),\n",
    "    \n",
    "    \"W_full_dropout\":tf.Variable(tf.random_normal(shape=[4096, 1024]), name='weight'),\n",
    "    \"b_full_dropout\":tf.Variable(tf.random_normal(shape=[1, 1024]), 'bias')\n",
    "}\n",
    "\n",
    "# Create model\n",
    "def conv_net(x,dropout):\n",
    "    with tf.name_scope('model') as scope:\n",
    "        # Reshape input picture\n",
    "        x = tf.reshape(x, shape=[-1, image_width, image_height, image_channel])\n",
    "\n",
    "        # Convolution Layer\n",
    "\n",
    "        # Max Pooling (down-sampling)\n",
    "        with tf.name_scope('layer1') as scope:\n",
    "            W_conv1 = variables_dict[\"W_conv1\"]\n",
    "            b_conv1 = variables_dict[\"b_conv1\"]\n",
    "            convOne = tf.nn.conv2d(x, W_conv1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "            reluOne = tf.nn.relu(convOne + b_conv1)\n",
    "            conv1 = tf.nn.max_pool(reluOne, ksize=[1,4,4,1],strides=[1,4,4,1],padding=\"SAME\")\n",
    "\n",
    "        # Convolution Layer\n",
    "        with tf.name_scope('layer2') as scope:\n",
    "            W_conv2 = variables_dict[\"W_conv2\"]\n",
    "            b_conv2 = variables_dict[\"b_conv2\"]\n",
    "            convTwo = tf.nn.conv2d(conv1, W_conv2, strides=[1,1,1,1], padding=\"SAME\")\n",
    "            reluTwo = tf.nn.relu(convTwo + b_conv2)\n",
    "            conv2 = tf.nn.max_pool(reluTwo, ksize=[1,4,4,1], strides=[1,4,4,1],padding=\"SAME\")\n",
    "\n",
    "        with tf.name_scope('layer3') as scope:\n",
    "            W_conv3 = variables_dict[\"W_conv3\"]\n",
    "            b_conv3 = variables_dict[\"b_conv3\"]\n",
    "            convThree = tf.nn.conv2d(conv2, W_conv3, strides=[1,1,1,1], padding=\"SAME\")\n",
    "            reluThree = tf.nn.relu(convThree + b_conv3)\n",
    "            conv3 = tf.nn.max_pool(reluThree, ksize=[1,2,2,1], strides=[1,2,2,1],padding=\"SAME\")\n",
    "            \n",
    "        # Fully connected layer\n",
    "        # Reshape conv2 output to fit fully connected layer input\n",
    "        with tf.name_scope('full_connect') as scope:\n",
    "            W_full = variables_dict[\"W_full\"]\n",
    "            b_full = variables_dict[\"b_full\"]\n",
    "            input_flat=tf.reshape(conv3, shape=[-1, 8 * 8 * 64])\n",
    "            fc1 = tf.nn.relu(tf.matmul(input_flat, W_full) + b_full) #relu函数使得最终的图片特征都大于等于0\n",
    "#             fc1 = tf.matmul(input_flat, W_full) + b_full\n",
    "\n",
    "        # Apply Dropout\n",
    "        with tf.name_scope('dropout_layer') as scope:\n",
    "            drop_out = tf.nn.dropout(fc1,keep_prob)\n",
    "\n",
    "        with tf.name_scope('full_connect_dropout') as scope:\n",
    "            W_full_dropout = variables_dict[\"W_full_dropout\"]\n",
    "            b_full_dropout = variables_dict[\"b_full_dropout\"]\n",
    "            full_connect_dropout = tf.matmul(drop_out, W_full_dropout) + b_full_dropout\n",
    "        \n",
    "        \n",
    "#         return fc1\n",
    "        return full_connect_dropout\n",
    "\n",
    "with tf.name_scope('whole_model') as scope:\n",
    "#     with tf.device('/gpu:0'):\n",
    "    img_one_rep = conv_net(X1, dropout=keep_prob)\n",
    "#     with tf.device('/gpu:1'):\n",
    "    img_two_rep = conv_net(X2, dropout=keep_prob)\n",
    "    \n",
    "    epsilon = 1e-12\n",
    "\n",
    "    normalized_one_rep = tf.nn.l2_normalize(img_one_rep, 1, name=\"normalized_one_rep\")\n",
    "    normalized_two_rep = tf.nn.l2_normalize(img_two_rep, 1, name=\"normalized_two_rep\")\n",
    "    \n",
    "    cos_rep = tf.reduce_sum(tf.mul(normalized_one_rep, normalized_two_rep), reduction_indices=1)\n",
    "    \n",
    "with tf.name_scope('result') as scope:\n",
    "    with tf.name_scope('norm_W'):\n",
    "        norm_W1 = tf.sqrt(tf.reduce_sum(tf.mul(variables_dict[\"W_conv1\"], variables_dict[\"W_conv1\"])))\n",
    "        norm_W2 = tf.sqrt(tf.reduce_sum(tf.mul(variables_dict[\"W_conv2\"], variables_dict[\"W_conv2\"])))\n",
    "        norm_W3 = tf.sqrt(tf.reduce_sum(tf.mul(variables_dict[\"W_conv3\"], variables_dict[\"W_conv3\"])))\n",
    "        norm_full = tf.sqrt(tf.reduce_sum(tf.mul(variables_dict[\"W_full\"], variables_dict[\"W_full\"])))\n",
    "        norm_W = norm_W1 + norm_W2 + norm_W3 + norm_full\n",
    "        \n",
    "    cross_entropy_cnn = tf.nn.sigmoid_cross_entropy_with_logits(logits=cos_rep * 10, targets=y)\n",
    "                                \n",
    "    cost = tf.reduce_sum(cross_entropy_cnn, name='cost')\n",
    "        \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost, global_step=global_step)\n",
    "    \n",
    "    cos_rep_gt_zero = tf.greater(cos_rep, 0)\n",
    "    label_gt_zero = tf.greater(y, 0.5)\n",
    "    correct_pred = tf.equal(cos_rep_gt_zero, label_gt_zero)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主入口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13701\n",
      "13701\n",
      "13701\n",
      "2741\n",
      "2741\n",
      "2741\n"
     ]
    }
   ],
   "source": [
    "# 获取《图片一，图片二，标记》数据对 ， label等于 0 或 +1\n",
    "image_one_path_list, image_two_path_list, label_list = load_data()  \n",
    "\n",
    "\n",
    "# 数据划分\n",
    "img_one_train, img_one_test, img_two_train, img_two_test, label_train, label_test = cross_validation.train_test_split(image_one_path_list, image_two_path_list, label_list, test_size= 0.2)\n",
    "print(len(img_one_test))\n",
    "print(len(img_two_test))\n",
    "print(len(label_test))\n",
    "\n",
    "# 获取图片数据\n",
    "# print(\"获取图片数据\")\n",
    "# images_one = load_image_with_path_list(img_one_train)\n",
    "# print(len(images_one))\n",
    "\n",
    "# images_two = load_image_with_path_list(img_two_train)\n",
    "# print(len(images_two))\n",
    "\n",
    "images_test_one = load_image_with_path_list(img_one_test)\n",
    "images_test_two = load_image_with_path_list(img_two_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range(100):\n",
    "#     fig = plt.figure()\n",
    "#     fig.add_subplot(1,2,1)\n",
    "#     plt.imshow(images_test_one[k])\n",
    "#     fig.add_subplot(1,2,2)\n",
    "#     plt.imshow(images_test_two[k])\n",
    "#     plt.show()\n",
    "#     print( str(label_test[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "random_a = random.random()\n",
    "resize_width = 128\n",
    "\n",
    "def get_image(image_path):  \n",
    "    \"\"\"Reads the jpg image from image_path. \n",
    "    Returns the image as a tf.float32 tensor \n",
    "    Args: \n",
    "        image_path: tf.string tensor \n",
    "    Reuturn: \n",
    "        the decoded jpeg image casted to float32 \n",
    "    \"\"\"  \n",
    "    content = tf.read_file(image_path)\n",
    "    tf_image = tf.image.decode_jpeg(content, channels=3)\n",
    "    \n",
    "    random_a = random.random()\n",
    "    if random_a < 0.3:\n",
    "        new_width = random.randint(resize_width, image_width)\n",
    "        tf_image = tf.image.resize_images(tf_image, [new_width, new_width]) ## 缩小\n",
    "        tf_image = tf.image.resize_image_with_crop_or_pad(tf_image, image_height, image_width) ## 填充\n",
    "    \n",
    "    random_a = random.random()\n",
    "    if random_a < 0.3:\n",
    "        tf_image = tf.image.random_flip_left_right(tf_image) ## 左右翻转\n",
    "    \n",
    "    random_a = random.random()\n",
    "    if random_a < 0.3:\n",
    "        tf_image = tf.image.random_brightness(tf_image, 0.2) ## 亮度调整\n",
    "    \n",
    "    random_a = random.random()\n",
    "    if random_a < 0.3:\n",
    "        random_dgree = random.randint(-30,30)  ## 旋转\n",
    "        pil_image = tf_image.eval()\n",
    "        rotated = misc.imrotate(pil_image, random_dgree)\n",
    "        tf_image = tf.convert_to_tensor(np.array(rotated))\n",
    "    \n",
    "#     random_a = random.random()\n",
    "#     if random_a < 0.3:   ## 平移\n",
    "#         random_left = random.randint(1, 30)\n",
    "#         random_up = random.randint(1, 30)\n",
    "#         random_right = random.randint(1, 30)\n",
    "#         random_down = random.randint(1, 30)\n",
    "        \n",
    "#         random_height = image_height - random_up - random_down\n",
    "#         random_width = image_width - random_left -  random_right\n",
    "        \n",
    "#         tf_image = tf.image.crop_to_bounding_box(tf_image, random_up, random_left, random_height, random_width)\n",
    "        \n",
    "#         random_pad_left = random.randint(0, image_width - random_width)\n",
    "#         random_pad_up = random.randint(0, image_height - random_height)\n",
    "#         tf_image = tf.image.pad_to_bounding_box(tf_image, random_pad_up, random_pad_left, image_height, image_width)\n",
    "        \n",
    "    \n",
    "    return tf_image\n",
    "\n",
    "## RunnerQueue\n",
    "train_input_queue = tf.train.slice_input_producer( [img_one_train, img_two_train, label_train], shuffle=True, capacity=10 * batch_size)  \n",
    "img_one_queue = get_image(train_input_queue[0])\n",
    "img_two_queue = get_image(train_input_queue[1])\n",
    "label_queue = train_input_queue[2]\n",
    "\n",
    "batch_img_one, batch_img_two, batch_label = tf.train.shuffle_batch([img_one_queue, img_two_queue, label_queue],\\\n",
    "                                                                   batch_size=batch_size,capacity =  10 + 10* batch_size,\\\n",
    "                                                                   min_after_dequeue = 10,num_threads=16,\\\n",
    "                                                                  shapes=[(image_width, image_height, image_channel),\\\n",
    "                                                                          (image_width, image_height, image_channel),()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:When passing a `Graph` object, please use the `graph` named argument instead of `graph_def`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "--------------------------------------------------step 0, training accuracy :0.5\n",
      "cos_rep_result:\n",
      "[ 0.98843759  0.85184222  0.93701923  0.9496848   0.99485016  0.99713147\n",
      "  0.90344638  0.98998165  0.95203692  0.92556989]\n",
      "learning_rate_val:0.1\n"
     ]
    }
   ],
   "source": [
    "cost_summary = tf.scalar_summary(\"cost\", cost)\n",
    "accuracy_summary = tf.scalar_summary(\"accuracy\", accuracy)\n",
    "norm_summary = tf.scalar_summary(\"norm_W\", norm_W)\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# config = tf.ConfigProto(log_device_placement=True)\n",
    "# sess = tf.Session(config=config)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "\n",
    "summary_op = tf.merge_summary([cost_summary, accuracy_summary, norm_summary])\n",
    "summary_writer = tf.train.SummaryWriter('/home/recsys/hzwangjian1/tensorboard/test', graph_def=sess.graph)\n",
    "\n",
    "\n",
    "coord = tf.train.Coordinator()  \n",
    "threads = tf.train.start_queue_runners(sess=sess,coord=coord)  \n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "for i in range(decay_step):\n",
    "\n",
    "    batch_img_one_val, batch_img_two_val, label = sess.run([batch_img_one, batch_img_two,batch_label])\n",
    "#     print(batch_im g_one_val.shape)\n",
    "#     print(label)\n",
    "    \n",
    "    if i% 50 == 0:\n",
    "        summary_str,train_accuracy,cos_rep_result,learning_rate_val  = sess.run([summary_op, accuracy, cos_rep, learning_rate],\\\n",
    "                                            feed_dict={X1:batch_img_one_val, X2:batch_img_two_val, y:label, keep_prob:(1.0)})\n",
    "\n",
    "        print(np.sum(label) * 1.0 / len(label))\n",
    "        print (\"--------------------------------------------------step \"+ str(i) +\", training accuracy :\"+ str(train_accuracy))\n",
    "        summary_writer.add_summary(summary_str, i)\n",
    "        print(\"cos_rep_result:\")\n",
    "        print(cos_rep_result[0:10])\n",
    "        print(\"learning_rate_val:\" + str(learning_rate_val))\n",
    "\n",
    "        if i > 3000:\n",
    "            for temp_index in range(len(label)):\n",
    "                if (label[temp_index] > 0.5 and cos_rep_result[temp_index] < 0) or (label[temp_index] < 0.5 and cos_rep_result[temp_index] > 0):\n",
    "                    fig = plt.figure()\n",
    "                    fig.add_subplot(1,2,1)\n",
    "                    plt.imshow(batch_img_one_val[temp_index])\n",
    "                    fig.add_subplot(1,2,2)\n",
    "                    plt.imshow(batch_img_two_val[temp_index])\n",
    "                    plt.show()\n",
    "                    print(str(label[temp_index]) + \"\\t\" + str(cos_rep_result[temp_index]))\n",
    "            \n",
    "\n",
    "#     cos_rep_result, cross_entropy_val, normalized_one_rep_result = sess.run([cos_rep, cross_entropy_cnn, normalized_one_rep],\\\n",
    "#                                                  feed_dict={X1:batch_img_one_val, X2:batch_img_two_val, y:label, keep_prob:1.0})\n",
    "#     print(\"cos_rep_result:\")\n",
    "#     print(cos_rep_result[0:10])\n",
    "    \n",
    "#     print(\"cross_entropy_val:\")\n",
    "#     print(cross_entropy_val)\n",
    "#     print(\"normalized_image_fea:\")\n",
    "#     print(normalized_one_rep_result[1])\n",
    "    \n",
    "    sess.run([optimizer], feed_dict={X1:batch_img_one_val, X2:batch_img_two_val, y:label, keep_prob:0.75})\n",
    "\n",
    "#     fig = plt.figure()\n",
    "#     fig.add_subplot(1,2,1)\n",
    "#     plt.imshow(batch_img_one_val[1])\n",
    "#     fig.add_subplot(1,2,2)\n",
    "#     plt.imshow(batch_img_two_val[1])\n",
    "#     plt.show()\n",
    "    \n",
    "print(\"training done\")\n",
    "coord.request_stop()  \n",
    "coord.join(threads)  \n",
    "summary_writer.close()\n",
    "\n",
    "saver.save(sess, model_path)\n",
    "\n",
    "print(\"===========================================TEST==============================================\")\n",
    "num_accuracy = 0\n",
    "total_num = 0\n",
    "\n",
    "# images_test_one = load_image_with_path_list(img_one_test)\n",
    "# images_test_two = load_image_with_path_list(img_two_test)\n",
    "\n",
    "print(len(label_test))\n",
    "for i in range(20):\n",
    "\n",
    "    batch_img_one_test = images_test_one[i * batch_size : (i+1) * batch_size]\n",
    "    batch_img_two_test = images_test_two[i * batch_size : (i+1) * batch_size]\n",
    "    batch_label_test = label_test[i*batch_size : (i+1) * batch_size]\n",
    "    \n",
    "    print(\"======================================================================================batch:\" + str(i))\n",
    "    \n",
    "    test_accuracy,cos_rep_gt_zero_val  = sess.run([accuracy, cos_rep_gt_zero],\\\n",
    "                             feed_dict={X1:batch_img_one_test, X2:batch_img_two_test, y:batch_label_test, keep_prob:(1.0)})\n",
    "    print(\"test_accuracy:\" + str(test_accuracy))\n",
    "    num_accuracy = num_accuracy + test_accuracy * batch_size\n",
    "    total_num = total_num + batch_size\n",
    "    \n",
    "    if i<= 2:\n",
    "        for k in range(batch_size):\n",
    "            fig = plt.figure()\n",
    "            fig.add_subplot(1,2,1)\n",
    "            plt.imshow(batch_img_one_test[k])\n",
    "            fig.add_subplot(1,2,2)\n",
    "            plt.imshow(batch_img_two_test[k])\n",
    "            plt.show()\n",
    "            print(str(cos_rep_gt_zero_val[k]) + \"\\t\" + str(batch_label_test[k]))\n",
    "\n",
    "\n",
    "print(\"num_accuracy:\" + str(num_accuracy))\n",
    "print(\"total_num:\" + str(total_num))\n",
    "print(\"test_accuracy_total:\" + str(num_accuracy * 1.0 / total_num))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "sess = tf.Session(config=config)\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, model_path)\n",
    "print(\"load model succeed!\")\n",
    "\n",
    "print(\"===========================================TEST==============================================\")\n",
    "num_accuracy = 0\n",
    "total_num = 0\n",
    "\n",
    "# images_test_one = load_image_with_path_list(img_one_test)\n",
    "# images_test_two = load_image_with_path_list(img_two_test)\n",
    "\n",
    "print(len(label_test))\n",
    "for i in range(20):\n",
    "\n",
    "    batch_img_one_test = images_test_one[i * batch_size : (i+1) * batch_size]\n",
    "    batch_img_two_test = images_test_two[i * batch_size : (i+1) * batch_size]\n",
    "    batch_label_test = label_test[i*batch_size : (i+1) * batch_size]\n",
    "    \n",
    "    print(\"======================================================================================batch:\" + str(i))\n",
    "    \n",
    "    test_accuracy,cos_rep_gt_zero_val  = sess.run([accuracy, cos_rep_gt_zero],\\\n",
    "                             feed_dict={X1:batch_img_one_test, X2:batch_img_two_test, y:batch_label_test, keep_prob:(1.0)})\n",
    "    print(\"test_accuracy:\" + str(test_accuracy))\n",
    "    num_accuracy = num_accuracy + test_accuracy * batch_size\n",
    "    total_num = total_num + batch_size\n",
    "    \n",
    "    if i<= 2:\n",
    "        for k in range(batch_size):\n",
    "            fig = plt.figure()\n",
    "            fig.add_subplot(1,2,1)\n",
    "            plt.imshow(batch_img_one_test[k])\n",
    "            fig.add_subplot(1,2,2)\n",
    "            plt.imshow(batch_img_two_test[k])\n",
    "            plt.show()\n",
    "            print(str(cos_rep_gt_zero_val[k]) + \"\\t\" + str(batch_label_test[k]))\n",
    "\n",
    "\n",
    "print(\"num_accuracy:\" + str(num_accuracy))\n",
    "print(\"total_num:\" + str(total_num))\n",
    "print(\"test_accuracy_total:\" + str(num_accuracy * 1.0 / total_num))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试模型加载并提取一幅图片的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "sess = tf.Session(config=config)\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, model_path)\n",
    "print(\"load model succeed!\")\n",
    "\n",
    "print(\"===========================================TEST==============================================\")\n",
    "num_accuracy = 0\n",
    "total_num = 0\n",
    "\n",
    "# images_test_one = load_image_with_path_list(img_one_test)\n",
    "# images_test_two = load_image_with_path_list(img_two_test)\n",
    "\n",
    "print(len(label_test))\n",
    "for i in range(20):\n",
    "\n",
    "    batch_img_one_test = images_test_one[i * batch_size : (i+1) * batch_size]\n",
    "    batch_img_two_test = images_test_two[i * batch_size : (i+1) * batch_size]\n",
    "    batch_label_test = label_test[i*batch_size : (i+1) * batch_size]\n",
    "    \n",
    "    print(\"======================================================================================batch:\" + str(i))\n",
    "    \n",
    "    test_accuracy,cos_rep_gt_zero_val  = sess.run([accuracy, cos_rep_gt_zero],\\\n",
    "                             feed_dict={X1:batch_img_one_test, X2:batch_img_two_test, y:batch_label_test, keep_prob:(1.0)})\n",
    "    print(\"test_accuracy:\" + str(test_accuracy))\n",
    "    num_accuracy = num_accuracy + test_accuracy * batch_size\n",
    "    total_num = total_num + batch_size\n",
    "    \n",
    "    if i<= 2:\n",
    "        for k in range(batch_size):\n",
    "            fig = plt.figure()\n",
    "            fig.add_subplot(1,2,1)\n",
    "            plt.imshow(batch_img_one_test[k])\n",
    "            fig.add_subplot(1,2,2)\n",
    "            plt.imshow(batch_img_two_test[k])\n",
    "            plt.show()\n",
    "            print(str(cos_rep_gt_zero_val[k]) + \"\\t\" + str(batch_label_test[k]))\n",
    "\n",
    "\n",
    "print(\"num_accuracy:\" + str(num_accuracy))\n",
    "print(\"total_num:\" + str(total_num))\n",
    "print(\"test_accuracy_total:\" + str(num_accuracy * 1.0 / total_num))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"===========================================TEST==============================================\")\n",
    "# num_accuracy = 0\n",
    "# total_num = 0\n",
    "\n",
    "# images_test_one = load_image_with_path_list(img_one_test)\n",
    "# images_test_two = load_image_with_path_list(img_two_test)\n",
    "\n",
    "# print(len(label_test))\n",
    "# for i in range(80):\n",
    "\n",
    "#     batch_img_one_test = images_test_one[i*batch_size : (i+1) * batch_size]\n",
    "#     batch_img_two_test = images_test_two[i*batch_size : (i+1) * batch_size]\n",
    "#     batch_label_test = label_test[i*batch_size : (i+1) * batch_size]\n",
    "    \n",
    "#     print(\"======================================================================================batch:\" + str(i))\n",
    "    \n",
    "#     test_accuracy,cos_rep_gt_zero_val  = sess.run([accuracy, cos_rep_gt_zero],\\\n",
    "#                              feed_dict={X1:batch_img_one_test, X2:batch_img_two_test, y:batch_label_test, keep_prob:(1.0)})\n",
    "#     print(\"test_accuracy:\" + str(test_accuracy))\n",
    "#     num_accuracy = num_accuracy + test_accuracy * batch_size\n",
    "#     total_num = total_num + batch_size\n",
    "    \n",
    "#     for k in range(batch_size):\n",
    "#         fig = plt.figure()\n",
    "#         fig.add_subplot(1,2,1)\n",
    "#         plt.imshow(batch_img_one_val[k])\n",
    "#         fig.add_subplot(1,2,2)\n",
    "#         plt.imshow(batch_img_two_val[k])\n",
    "#         plt.show()\n",
    "#         print(cos_rep_gt_zero_val[k])\n",
    "\n",
    "\n",
    "# print(\"num_accuracy:\" + str(num_accuracy))\n",
    "# print(\"total_num:\" + str(total_num))\n",
    "# print(\"test_accuracy_total:\" + str(num_accuracy * 1.0 / total_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del images_one\n",
    "# del images_two\n",
    "\n",
    "# index = 98\n",
    "# print(images_one[index].shape)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# fig.add_subplot(1,2,1)\n",
    "# plt.imshow(images_one[index])\n",
    "# fig.add_subplot(1,2,2)\n",
    "# plt.imshow(images_two[index])\n",
    "# plt.show()\n",
    "\n",
    "# print(len(images_one[1:5]))\n",
    "\n",
    "# print(label_train[index])\n",
    "\n",
    "# index_test = 98\n",
    "# fig = plt.figure()\n",
    "# fig.add_subplot(1,2,1)\n",
    "# plt.imshow(images_test_one[index_test])\n",
    "# fig.add_subplot(1,2,2)\n",
    "# plt.imshow(images_test_two[index_test])\n",
    "# plt.show()\n",
    "\n",
    "# print(label_test[index_test])\n",
    "\n",
    "\n",
    "# print( random.randint(0,len(img_one_train) - batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}